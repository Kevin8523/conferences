# Domino Data Science Pop-Up 2018 (2018-09-19)
#### Austin, Texas

## <a id='0'>Overview </a> 
- <a href='#1'>Navigating Interpretable vs Predictable Models by Josh Poduska (Chief DS / Domino Data Lab)</a> 
- <a href='#2'>Product(ive) Data Science by Julie Hollek (Senior DS / Twitter)</a>
- <a href='#3'>Keynote by Doug Schmitt (President / Dell EMC)</a>
- <a href='#4'>Detecting and Preventing Cybersecurity Threats Using Machine Learning by Stefano Meschiari (Senior DS / Duo Security)</a>
- <a href='#5'>Panel: Creating a Data Science Flywheel</a>
- <a href='#6'>Fostering Collaborative Learning Environments and Loyal Data Science Teams by Randi Ludwig (DS / Dell)</a>
- <a href='#7'>Workshop: Best Practices for Managing the Data Science Lifecycle by Jithin George (SeniorEngineer / Domino Data Lab)</a>
- <a href='#8'>Themes</a>

## <a id='1'>Navigating Interpretable vs Predictable Models by Josh Poduska (Domino Data Lab)</a>
	- Two kinds of Interpretable Models
		+ Global & Local interpretability
		+ Global: System as a whole
			* Global is to try to visualize an entire structure
			* Try to find strong association between inputs and targets
			* Hypothesis testing - Prove or establish 
			* Given dataset and trying to find structure in dataset
		+ Local:
			* Made this prediction, need to understand why this prediction was made
			* Want to find the error, the confidence interval behind the prediction
	- Example of 3 Models
		+ Model 1 - Accuracy / Predictive
			* Image Classification
			* Language translation
			* Day trading of Stocks
		+ Model 2 - Explanatory: i.e: In general: bright pics are centered dark areas, green objects on edge are plants, and near perfect circles are man-made. Tickets example
			* Root cause failure determiniation
			* Qunatify the impact of tweets on stock price
			* Studying the causes of student success
		+ Model 3 - Model said this was a black bear BECAUSE of this super-pixel object. Tells you the why. Tickets example: .2 multi ticket because x, .6 beause of x2
			* Customer Churn
			* Disease diagnosis
			* Customer Segmentation
	- Why do we care about model interpretability?
		+ Model ethics,bias and misuse
		+ Regulatory Purposes
		+ Trust and understanding
			* If consumers or users dont trust your models, it has a high likelihood to be shelfed and not used
	- Starting a project:
		+ Explanatory vs Predictive: What does the end user want? Predicting or understanding why (explanatory)
			* Engine failure example: Wanted explanatory and didnt care about prediction
			* Student dropout example: Predict and understand why to correct it
		+ Interpretable Model: look for function f that best predicts F (theory)
			* minimize bias, estalbish causation of x to y, true to theortical model, finding the best f to match F, capture physical structure, explain why, quantifying effect each input has on the response.
		+ Predictive Model: Look for function f that best predicts future y (actual)
			* minimize variance first, association not causation, predicting y
		+ Holy Grail: to find a model f that predicts future y while keeping the structure of F
	- Global Interpretability: best to worst
		+ Linear Regression (coefficient analysis): coefficients to explain holding things constant how much does 1 unit change of x effect y
		+ Partial dependency plots: Effect of different input holding everything else constant
		+ Decision Trees: 
		+ Variable importance: __Relative__
	- Local Interpretability:
		+ Time to ingest data, human has time to ingest data & give feedback
		+ Using linear regression to quantify how much each feature applies to the end prediction
		+ Using decision tree to give clusters
		+ lime: great package for local interpretability
			* I.e: Which factor is because of heart diseases, why an image classified an observation as a bear
		+ Understanding error with a confidence interval. 
	- When are both needed?
		+ Go for optimum accuracy then go to lime
		+ Global inference is critical, usually have to sacrafice predictive power
		+ Figure out what is more important
			* Scientist - Global interpretability: Understand at a highlevel how does this thing work
			* Managers - 
		+ Models: Goes from Predictive to less predictive (less interpretable to interpretable)
			* NN, GBM, RF combined with a variable importance graph
			* DT, Elastic Net, Naive Bayes - Better for global interpretability but less predictive
			* GLMM - More explainability but less predictive - Allows inference
			* Causal Inference: Judea Pearl (Jew-dee-uh) - Have to have a preconcieved hypothesis for it to work. I.e: I think x1 + x2 causes y
	- Tips to do in practice:
		+ What is the goal of the project
		+ What decision will be made or influenced as a direct result of project
		+ Who will make the decision (persion, machine)
		+ How will they consme the output of th emodel
		+ What kind of model output is needed (score/prob, binary pred, quantiy)
		+ How important is it to explain
		+ Most used - Gradient boost, GLMMs, Random Forest, NN
		+ Naive bayes gives coefficient but assumes independence for features
		+ Understand what the customer want to find the best model.
			* How does real life scenario work?
			* How is results/model going to be used
			* Each model has assumptions that need to mimic real life scenario
	- Example workflow of determining model type
		1. Have a plan
			+ Predictive
		2. Interpretable & Predictive: Local or Global
			+ Local GO all out predictive followed by LIME, other options: decison tree, enet, NB, baseline with GLMM and coeff analysis
			+ Global: NN, GBM, RF with variable importance, other options: decison tree, enet, NB, baseline with GLMM and coeff analysis, consider casual inference.
		3. Interpretable:
			+ Can collect data - DOE, GLMMs, RSM
			+ Observational Data - GLM, consider casual inferece or SEM
	- Intreptable to Not interpretable
		+ CI, DOE, RSM, GLMMMs, DT, ENET, Step regression
	- What does lime do?
		+ Model to predict x vs o
		+ non linear model
		+ Hard to explain globally how it made its decision
		+ Lets take one observation o, why global model classified it as 0, moves the observation around and understand why it is classfiied the way it is. Uses the distance in n-dimenssional space to understand and gives it a weight. Builds a linear model based on this to explain 
		+ Example of lime on data:
			* iris dataset: Gives features and if it satisfies its rules, it will drop by x%
			* Approximating how the model works in the "local" / little environment
			* Can create a new lime model for the observations in the outer limits
			* Example on Domino Trial

	- Things to lookup:
		+ GDPR
		+ anchor lime

	- My Takeaways:
		+ Two types of interpretable models, global & local
			+ global is
		+ Lime: great package for local interpretability
			+ Run lime after running models
		+ Understand what the customer want to find the best model.
			* How does real life scenario work?
			* How is results/model going to be used
			* Each model has assumptions that need to mimic real life scenario


## <a id='2'>Product(ive) Data Science by Julie Hollek (Senior DS / Twitter)</a>
	- Product Data Science - Support product metrics & investigation & make people around you better at their job
		+ Metrics - How the company views your product
		+ insights into customers' experiences
		+ Measure success & failures
		+ monitor health of the product
	- Lifecycle of ML workflow
		+ Hierarchy of needs: logs, data sets, features/heuristics, ml model, ml in product
	- Data Exploration
		+ Opportunity sizing/prototyping: test to see if theres an audience
		+ experimentation: Test hypothesis, find casual impact with a/b tests
		+ impace analyses: Find correlational trends, useful when you cant A/B Test
	- Product DS
		+ Sales: Network & translate their business problems to data & answers
		+ Engineer: ETL
		+ Marketing: Need to understand how to implement and users to understand your work
		+ Product Management: New ways to implement models / work to completion
		+ Communication: Translate business problem to data questions. EMPATHIZE with your users. Listen to understand, explain in their lanaguage.
	- Communication tips:
		+ Visualize: 
			* Translate your work into images, tables, graphs to tell a story
			* Provide Context through text or visuals
			* Use data visualization best practices: pre-attentive processing
		+ Empathize: 
			* SQVID:
			* S: Simple      <----->   Elaborate
			* Q: Quality     <----->   Quantity
			* V: Vision      <----->   Execution
			* I: Individual  <----->   Comparison
			* D: Difference  <----->   Now
		+ Simplify
			* Boiling down the work to insights:
			* Give context & insight

	- Things to lookup:
		+ SciPy
		+ interactive.twitter.com
		+ Dan 2018 Scipy (Visualization)
		+ Some chick 2017 Scipy talk (Visualization)

	- My Takeaways:
		+ Communication is overlooked and very important for a DS. 
			+ Visualize
			+ Empathize
			+ Simplify
		+ SQVID Model: Simple, Quality, Vision, Individual, Difference


## <a id='3'>Keynote by Doug Schmitt (President / Dell EMC)</a>
	- Measurement for success from model ideation through post-production:
		1. Customer Impact
			* How do we take this information and impact the customers in a positive way
			* This will lead to Revenue & Cost
			* i.e: Netflix Recommendation system
		2. Revenue
			* 
		3. Cost
			* If you focus on this, you become project oriented
	- What is #1 factor for DS success
		+ Collaboration
			* Changes the model for busienss
			* Accelerates Feedback loops & iteration
			* Reduces reptition / redundancy
			* Drives better end results
			* Maximizes relevances
			* Contributes to thriving culture
			* Sparks Innovation
			* Cooperative Ownership
				* Ensure DS project aligns with business goals
				* Encourages collaboration across business units
				* Keeps everyone accountable
				* Increase tangible results
				* Reinforce end goal, become model-driven by weaving data science throughout business fabric
	- Decentralize DS, having DS skillset across the business in different Business areas

	- My Takeaways:
		+ Collaboration is key to DS Success


## <a id='4'>Detecting and Preventing Cybersecurity Threats Using Machine Learning by Stefano Meschiari (Senior DS / Duo Security)</a>
	- What is Threat Detection?
		+ Unwanted activity
	- Key Terms
		+ Phishing: Spoof Website; Data breaches
		+ Malware: Keyloggers
		+ Breaking and leveraging weak credentials
	- Statisics
		+ 2 billion users had threat 
	- Objective: Recognize activity pattern witahin an access log that are indicative of policy violations or breaches
	- System (Current State): Many automated threat detection system are based around signatures and static rules
	- ML Alg: Anomaly Detection:
		+ Recognize patterns outside the norm
		+ Might not look like any other attacks we've seen: Novel Attack
	- Problems:
		+ Annoying data
		+ Lack of labels
			* Attacks are rare
			* Unsupervised Models
			* Strong assumptions on normality vs attack
			* Without ground truth you cant verify your assumptions easily
		+ Diversity of benign behavior
			* We assume normal behavior is uniform & frequent
			* In reality, diverse benign behavior across multiple users
		+ Anomaly does not mean threat
			* Lots of noise in the data
		+ High cost of mispredictions
			* False Positives: Loss of time & trust
			* False Negatives: Data Breaches
	- Components of a Usable Threat Detection System
		+ Explanation : Justify model decisons
		+ Context: Provide contextual behavioral information
		+ Risk Score: Priroritze events
		+ Feedback: Human in the loop, knowledge transfer
		+ Action: suggest next steps & mitigations
	- Lesson Learned:
		+ Keep your scope small (but relevant): Focus on use case / ie: 1 specific threat or attack
		+ Production is not Research: Keep both in mind when building a pipeline
			* Production: Want relaibility
			* Research: Ease of access, iterative
		+ Figure out the monitoring story early
		+ Dont trust your labels Implicitly
			* Understand if labels are correct
			* Feedback were systematically bias (Subset of users): Not learning from fraudlent activity but just that subset group
		+ Ask your Operators (SMEs)
			* You dont have to wait for your models to be perfect
			* Core group of customers you can test your models with AS EARLY AS POSSIBLE
			* Get feedback early and often
				- What do they consider suspicous vs merely anomalous? What is useful?
				- Dave does X all the time when Y happens, and its not suspicious
				- Get a good usecases rare in the customer base at large
		+ Business metric is whether your end user find predictions useful and usable


## <a id='5'>Panel: Creating a Data Science Flywheel</a>
	- Panel: 
		+ Host: Ron Green, CTO Kungfu.ai
		+ Jon Lyens, Chief Product Officer, Data.world
		+ Caitlin Hudson, Senior DS, Shelfbucks
		+ Chris Burns, AI & ML Solution Architect, AWS
	- Reproduciability in the workplace:
		+ Process & Team culture
		+ Through reproduciability people can learn what you're doing
			* Peer Review
			* Code Review
			* Invite questions and critique
		+ Jupyter Notebooks??
	- DS as a team sport
		+ DS team & Business user 
		+ Bring in business users early in the process for feedback & guidelines
			* Bring in DS & business users during ideation
	- Projects will deliver value
		+ Delivering results
		+ Does it answer the original business problem & build upon that
			* Focused problem & solution
	- Balancing Requirement Gathering
		+ Business question is when DS should be brought in
		+ Process of DS: business question >> data for business question >> results/answer from data >> translate back to business answer
	- Pros & Cons of different DS team structure
		+ Product team: Product owners & 1 DS
			* Good business knowledge
		+ DS team: Multiple DS
			* Bounce ideas for Algorithims
			* Establish best practices
	- Operationalize Models for production
		+ What % do I trust a model...is this acceptable for the business
		+ Update Models, they will deterioriate over time because the real world data changes
		+ Watch the new data come in, models will deterioriate 
		+ Track Model scores overtime:
			* Home spun scoring: 
			* Build in scoring of the model in the production pipeline
	- How do you get customers to deal with failure
		+ Be open and honest: I'll test out 6-7 scenario/hypothesis, but they might not work
		+ Be transparent with the customers
		+ Try quick wins with customers so business can see value quickly
		+ Communication is keys
	- Tips: 
		+ Establish business context, become a business SME 
		+ Maintence of model is just as important as creating of model. Understand how you are maintaing your model
		+ What additional data do we need for better results/analysis
		+ Data Science answers a question/hypothesis. Even saying there is no correlation is an answer
		+ Save your models to have copies of these iterations:
		+ Feature engineering: Have to have the business knowledge to do great feature engineering


## <a id='6'>Fostering Collaborative Learning Environments and Loyal Data Science Teams by Randi Ludwig (DS / Dell)</a>
	- Continuous learning >> As a Data Scientist
	- Best Practice for Learning DS
		+ Not lecture-based >> Be interactive, have discussions, Learn by doing & learn by teaching
		+ Sample workflow:
			* Students gather evidence
			* Use Evidence to convince teammates
			* Come to concensus as class
		+ Practices
			* Pair programming
			* Real time troubleshooting
		+ Sample Technology
			* Github
			* Slack
	- How to build communities
		+ Local networking events: Meetups
		+ Watch Conference Talks together: Lunch & learn
		+ Team across company present their DS work: Presentation
		+ Online troubleshooting: Slack
		+ Integrate asipiring DS into a project 
	- Commonalities:
		+ Main Practices
			* Learn by Doing
			* Learn by Teaching
			* Communities
		+ Main Principles
			* Build Trust / Relationships
				- Build environment for people to ask questions
			* Open line of communications
				- Provide a platform + Moderators
				- Keep the conversation going, makes it worthwhile
				- Open all the time, not just when you're together: Slack
			* Curated resources
				- Enable Future Learning
				- Keep it in a central repositiory (Github, wiki)
			* Incentives
				- Make it Worth the time: getting a grade, job, meeting executives
				- Give time & credit
	- Teaching Statistics & Practices
		+ Average attention span: 45 minutes
		+ For work > 45 min, break up the time so its not > 45 minutes


## <a id='7'>Workshop: Best Practices for Managing the Data Science Lifecycle by Jithin George (SeniorEngineer / Domino Data Lab)</a>
	- Did not attend this talk

## <a id='8'>Takeaways & Themes</a>
	- Theme:
		+ Collaboration
		+ Communication & Empathize
		+ Cater to users for solutions: Interpretability vs Predictive
	- Random Ideas: 
		+ Best practices for visualizing data in 4d ++
			* Color, sounds, symbols, 
		+ A way to take a picture of powerpoint through your laptop....
			* Connect phone directly to laptop
			* 