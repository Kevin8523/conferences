# Summary of Predictive Analytics World 2018

# <a id='0'>Predictive Analytics World 2018-06-05 </a> 
- <a href='#1'>1. Business World</a>
    - <a href='#1-1'>1.1 Dean Abbott - How Predictive Modelers Should Use Data to Tell Data Stories</a>
    - <a href='#1-2'>1.2 Dean Abbott & Karl Rexer - Ask Dean and Karl Anything</a>
    - <a href='#1-3'>1.3 Vivek Agarwal, Steven Ramirez, Morgan Vawter - Operationalizing Machine Learning: How to Ensure Value-Driven Deployment</a>    
- <a href='#2'>2. Deep Learning World</a>
    - <a href='#2-1'>2.1 James McCaffrey - LSTM Nerual Networks for Time Series Analysis</a>
    - <a href='#2-2'>2.2 Luka Gluokhova - Deep Learning: Capabilities Realized and New Frontiers</a>
- <a href='#3'>3. Workshops</a>
    - <a href='#3-1'>3.1 James McCaffrey & Ricky Loynd - Deep Learning in Practice: A Hands-On Introduction</a>
    - <a href='#3-2'>3.2 John Elder - The Deadly Dozen: The Top 12 Analytics Mistakes and the Techniques to Defeat Them</a>
- <a href='#4'> 4. Takeaways & Themes</a>
- <a href='#4'> 5. iNterpret Data: Give Insights</a>

## <a id='1'>1. Business World</a>
### <a id='1-1'>1.1 Dean Abbott - How Predictive Modelers Should Use Data to Tell Data Stories</a>
### Dean Abbott - How Predictive Modelers Should Use Data to Tell Data Stories
	1. Know your building blocks, understand the data and what you are visualizing
	2. What is the main point you are trying to communicate to the end user? This will tell you how you shape your visual.
		- Truncate axis
		- Log transform the data
	3. If you are trying to display comparisons, they are best if made on the same page
	4. Tell the story you need to tell, but be transparent about the biases 
		- Scale
			a. Normalize Scales: Remove magnitude bias
			b. Visuals by Percentage
		- Add expected results: Priors
			EXAMPLE GIVEN
			a. X-axis: % of Bush vote by county / % republican registrants 
			b. Y-axis: % of Buchanan vote by county / % reform party registrants
	5. When presenting to clients, start simple
		- Example - Use decision tree to tell the story
			a. If you agree facilities are clean and you feel welcomed then 72% felt satisfied
			b. If someone feels unwelcomed at the Y then do x, y, z
	6. White space is importnat to show seperation. Case by case on how white spaces should be used
	7. Bring stakeholders early and present findings often
	8. Whenever you find interesting insights in the data, show leadership early and see how they react. If they're scratching their heads, find a different way to visualize.
My Takeaways
	- Know your building blocks and how to use them
	- Understand your biases because every visual is biased
	- Know your audience & tell a data story that the audience understand

### <a id='1-2'>1.2 Dean Abbott & Karl Rexer - Ask Dean and Karl Anything</a>
### Dean Abbott & Karl Rexer - Ask Dean and Karl Anything 
Questions during the Session
	1. What are the best resources for data visualization?
		- Edward Tuffe
		- Steven few 
		- Kiser Fung
		- Tim and Dan (Vlamos Brothers)
			a. Color Pallete Recommendations
			b. B.I. Reporting
		- Flowing Data
		- R color Brewer
	2. How do you communicate with non-technical people
		- Speak using their terminology
		- Example: Take a model scores and show the ten deciles. Of each of the deciles what is the % target on that decile.
		- Example: Show Simple model of decison tree to explain the model and then show a complicated model and explain the tradeoff from going to a complicated model. More appreciation from clients.
		- Understand what the customer wants: Example Question: What profit do I expect based upon this rank order? Instead of Mean Square Error use a Lift Chart / Gain Chart if the customer needs only top records. Case by case specific. 
		- Modelers think "on average" and Customers think on "specific cases"
	3. What is your view on the purpose of Deep Learning?
		- For non-linear data its better
		- Interpretability vs Accuracy tradeoff with Deep Learning
		- Still do feature engineering in your model to help the model do the work
		- Ratio features hard to do so you should feature engineer for the DL models.
		(Difference in opinion on the feature engineering for DL model with other speakers)
	4. What is one tip or best practice you learned throughout your career as a Data Scientist
		- Dean Abbott
			a. Be Humble
			b. Dont assume
			c. Data itself is only one part of the story
			d. Understand what you model is doing - Examples - Building a model on tanks vs truck and found great initial results. Later found out that the classifier was picking up on the edges and not actually learning from the data. 
			Algorithim just learns from data, it does not have common sense
			e. Have people shoot holes in your model, better to catch it early
		- Karl Rexer
			a. Be really focused at the beginning, you're solving a business problem so make sure you satisfy those requirements. Have the models foused on what it needs to be focused on
			b. Selection of the target variable you're solving - Make sure it is clear and concise. More important than a 1% improvement to model accuracy
			Example: Loan Default - Instead of using if there was a default on the loan, ended up using if it was a profitable deal. When we score we use profitability as a target, since this is most closely related to the business decision they want to make. 
			c. Understand your customer - Example - Some banks want to know if core checking account goes to another account, some care about balance decline, and there are others that care if all bank accounts close out.
			Understand how the specific business problem and how the business wants to act on it.
			d. Don't ASSUME - Example - Managers all had a different definiton of churn. Account to my name, Account to my whole family, etc.
			e. Measurement of what a Good Model is: Know the Business question and how it translate into the model effectiveness. Example - Client only cares about top 50% of rank so the accuracy only matters for the top half.
				- Could effect which model you chooose.
					1. Average Squared Error
					2. By Deciles
					3. Knowing how you are trading off errors
					4. Model had to excel at the top 100, the rest didn't matter
			f. Get your business partner to agree in writing on requirement to avoid scope creep.
			g. Feature engineering - Be creative, create a missing value flag as a variable. Data is missing for a reason, what knowledge can you extract from this. Whether you get a data match or not is a feature. Example - Add BMI as a feature
	5. Getting Customer Adoption
		a. Use Same Terminology. Explain to them in metrics they use and explain downside or costs. Example - Navy Seals wanted a "Rudy" story and to find more candidates like that. They are tough to find and have a lower % success rate. Show the cost vs gain of targeting those canidates and show wthe downside or cost. 
		b. Example - Customers just wanting the data in Excel - Understand pain points and why they take things into excel. From there understand how we can provide more efficiency. 
	6. Use Case of using External data not initially given but thinking about how to solve the problem
		a. Client wanted to find recruits who did well in Submarine. Can we ideentify in advance if they will do well? Understand the problem and that the best feature was data of people already out in submarine, so learn from that to find recruits. 
My Takeaways
	Be humble, try to avoid making assumptions, every problem is unique so it should be treated that way, and empathize with the client for best results.

### <a id='1-3'>1.3 Vivek Agarwal, Steven Ramirez, Morgan Vawter - Operationalizing Machine Learning: How to Ensure Value-Driven Deployment</a>
### Vivek Agarwal, Steven Ramirez, Morgan Vawter - Operationalizing Machine Learning: How to Ensure Value-Driven Deployment?
	1. Key things to ask when deploying models:
		- Keep in mind speed of models when deploying & creating models
		- Are there any end users?
		- Scalability
		- User Acquisitions & retention
			a. No user, no value
		- Integrate into the business process
	2. Things to do when deploying models:
		- Leverage domain expertise
		- Focus on answering business problem
		- Re-calibrate models regularly
		- Keep in mind size and scale: If downstream process is using models, keep this in mind
	3. Things to AVOID when deploying models:
		- Discuss algorithims:
			a. Discuss impact (customer's algorithim)
		- Believe in out of box A.I.
			a. Set realistic expectations
	4. How to operate when dropping into a new situation / company:
		- Current state analysis
			a. Pockets of excellence in analysis
		- Get vision from both executive and operating managers
		- Starts with business understanding and leads to scaling up and taking advantage of data
		- Strategic framework
			a. Deployment
			b. Re-training & testing model
		- Measure of success and get stakeholders alignment
		- Having solid communication channel across organization
	5. Working on $0 ROI projects but improving morale
		- Customer loyalty is a value driving metric we need to account for
	6. Keep in mind how clients measure success
		- Example - Increase Sales

## <a id='2'>2. Deep Learning World</a>
### <a id='2-1'>2.1 James McCaffrey - LSTM Nerual Networks for Time Series Analysis</a>
### James McCaffrey - LSTM Nerual Networks for Time Series Analysis
	- Working with Time series data: Difficult
		a. Sequence Data, just counts and sequential
		b. Naive model, common mistakes missed: Using the previous score as a prediction for the next prediction. Need to take this into account when modeling for time-series
		c. For Forecast: Predicting Ahead
		d. For Anomaly Detection: Fit the entire sequence and locate historically where are the anomaly detections.
	- Different technique based on:
		a. Seasonality
		b. Length of time series
	- Technqiues used in time series data:
		a. SES: Simple exponential smoothing
			• Alpha - smoothing parameter
			• No y just an x
		b. AR: Autoregression (autoregressor)
			• Difference from SES, 1 parameter alpha
		c. MA: Moving Average
			• People can use it, but its very hard to fit
	- What is the deep in a Deep Neural Network?
		a. 2 or more hidden layer in a neural network
	- LSTM: Long short-term memory
		a. Has a state
		b. Has memory
		c. Originally created for NLP
		d. New output is dependent on current input and previous output
		e. Great for sequences of words or characters and great for sequences of numeric value
		d. Requires lots of hyper parameter tuning to get a good model
	- Example - LSTM Airline Passenger - **Slides cover most of the details**
		a. Getting things in the right shape to get the system to ingest the data
		b. Units in LSTM represents the cell size, the amount the LSTM remmebers (memory)
		c. Hyper Parameter tuning:
			• Higher unit means it remembers more, including junk
			• Too low it doesn’t remember enough
Takeaways
	- Few people demonstrating success but lots of LSTM questions being asked
	- Setting the hyperparmeter is very difficult but important. 
		a. If Sequences too short: LSTM might predict xt-1 (the previous month)
		b. If sequences are too long: does time series even make sense at all?
		c. Bad Sequences: LSTM might memorize all training sequences and instead of creating a good model it memorizes the data.
	- LSTMs can be effective but are on the brittle side. Requires hyperparameter tuning
		a. Remember, tuning for forecasting and anomaly detection are different so you should tune them differently
	- Things to look at:
		a. Will RNN LSTM attention help?
		b. Will clever feature engineering help?
		c. Will very deep architecture LSTM help?
		d. Can CNNs be useful
		e. LSTMs for TSR may have big breakthrough
		f. Standard DNNs appear to be quite useful for modeling over entire range (anomaly detection)

### <a id='2-2'>2.2 Luka Gluokhova - Deep Learning: Capabilities Realized and New Frontiers</a>
### Luka Gluokhova - Deep Learning: Capabilities Realized and New Frontiers
	- What is the biggest risk introduced by run-time reliance of deployed deep learning models?
		1. Interpretability
		2. Getting insights and not being able to derive value
		3. Inherent risk in the modeling framework itself
			a. Adversarial Attacks - There are 3 types of adversarial attacks
				i. White Box: Sees Everything
				ii. Grey Box: Can see results but not code
				iii. Black Box: Only see repercussions 
			b. Example of Adversarial Attacks
				i. Fooling a website
				ii. Spray painting on a stop sign to fool a self driving car
				iii. Malware as legitimate content
	- Counter Measures
		1. Inject Adversarial attacks in our training process
			a. Adversarial Training
				i. ICN (Introspective Convloutional Network)
					• Create adversarial attacks to make the decision bundary tighten around a specific class.
					• Might build an unmalleable model
				ii. Defensive Distilation
					• Building a model on top with the decision boundaries smoothed
				iii. Feature Squeezing
					• More reactive than proactive
					• See if the new incoming data is an attack or real data
				iv. Gradient Masking
					• Making the gradient inaccessible to the attacker
Takeaways
	- Different techniques to counteract against the inherent risks when deploing a Deep learning model.

## <a id='3'>3. Workshops</a>
### <a id='3-1'>3.1 James McCaffrey & Ricky Loynd - Deep Learning in Practice: A Hands-On Introduction</a>
### <a id='3-2'>3.2 John Elder - The Deadly Dozen: The Top 12 Analytics Mistakes and the Techniques to Defeat Them</a>

## <a id='4'>4. Takeaways & Themes</a>
### Takeaways & Themes from Conference
	1. UI / UX is BIG, don't overlook it
	2. How to Operate for a comptitive advantage
		- Speed of delivery & iteration speed: React quickly and iterate - You have no idea of the unknown unknowns
		- Seperation of elements (Data - Model - Interface)
			a. Data: focus on data quality
			b. Model: Like research project, we cant promise accuracy but we are investigating
			c. Interface: How is the client going to use it and how will it be useful
		- Deep understanding of how the tool is used: UI / UX
		- Get to the MVP (Minimum Viable Product)
		- Agile Methodology
		- Focus on process and repeatability
	3. Data is King: Garbage in, garbage out. Models can't help crap data, good data eats algorithims for breakfast.
	4. Speak to industry experts to add to the model. If the model doesn't reflect what the expert says, you should at least question the model.
	5. Plan top-down, but build bottom-up
		- Getting executive sponsohip makes it easier to get bottom-up support
	6. Best Data Scientist get out and talk to people
		- Understanding the business problem and what they are really after
		- If it is even useful to change their actions
	7. Start small and interate with fast feedback
		- Control yourself from jumping into the ocean of data: Restrict yourself from this
	8. Focus on adoption for scalable success
		- In the platform set up a message box
		- Button to vote if they like the prediction: Used this data as a tuning parameter for future models
	9. Educate clients - Machines help redesign of jobs, not stealing jobs
	10. Too much money is spent on technology rather than execution of analytics.
	11. Complacency in companies is like waiting for death
	12. Benefits of bayesian: Prior information can improve regression & Hierarchy can be a part of the prior
	13. Build a strong foundation for analytics by developing DELTA: Framework for Success
		- Data
		- Enterprise
		- Leadership
		- Targets
		- Analysts
	14. Balance focus on the organizational and techinical aspects of analytics
	15. Think big, start small and optimize results
	